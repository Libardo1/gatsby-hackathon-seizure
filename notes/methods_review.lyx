#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Methods review
\end_layout

\begin_layout Date
9 November 2014
\end_layout

\begin_layout Section
Seizure detection
\end_layout

\begin_layout Subsection*
Seizure detection winner
\end_layout

\begin_layout Standard
The code and documentation can be find at:
\end_layout

\begin_layout Standard
\begin_inset CommandInset href
LatexCommand href
name "https://github.com/MichaelHills/seizure-detection"
target "https://github.com/MichaelHills/seizure-detection"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset href
LatexCommand href
name "https://github.com/MichaelHills/seizure-detection/raw/master/seizure-detection.pdf"
target "https://github.com/MichaelHills/seizure-detection/raw/master/seizure-detection.pdf"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Standard
Summary of the methods used:
\end_layout

\begin_layout Enumerate
Feature vector: FFT 1-47Hz + inter-channel correlation coefficients, CC,
 both in time and frequency domains + CC matrix eigenvalues in both time
 and frequency domains.
\end_layout

\begin_layout Enumerate
Classifier: per-patient Random Forest classifiers (3000 trees), trained
 on data from each patient.
\end_layout

\begin_layout Subsection
Feature extraction
\end_layout

\begin_layout Standard
Features were kept or discarded based on their cross-validation performance.
 Combinations of multiple features eventually proved to provide a better
 classification score once the right features were combined.
\end_layout

\begin_layout Standard
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Standard
Three sources of features are used to form the whole feature-set:
\end_layout

\begin_layout Enumerate
log10(FFT magnitudes) in the low frequency range 1-47 Hz.
 
\end_layout

\begin_deeper
\begin_layout Standard
This frequency range offered the best result compared to other frequency
 ranges.
 These features alone, combined with the selected classifier (Random Forest),
 offered already excellent performance.
\end_layout

\begin_layout Standard
FFT magnitudes matrix dimensions: 
\begin_inset Formula $(\#_{channels}*47$
\end_inset

).
\end_layout

\end_deeper
\begin_layout Enumerate
Correlation coefficients, CC, between EEG channels
\end_layout

\begin_deeper
\begin_layout Standard
The FFT magnitudes matrix is first normalized across frequencies, column
 by column, subtracting the mean and dividing by the std.
 The correlation coefficient CC matrix 
\begin_inset Formula $(\#_{channels}*\#_{channels})$
\end_inset

 is then calculated for this normalized matrix.
 Finally, just the upper triangular matrix is taken for the features, as
 taking the whole matrix would be redundant.
\end_layout

\begin_layout Standard
The same is performed using the time-series data (not sure about the normalizati
on), by computing the CC matrix from the original data matrix with dimensions
 
\begin_inset Formula $(\#_{channels}*time)$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Enumerate
Eigenvalues 
\end_layout

\begin_deeper
\begin_layout Standard
Eigenvalues are computed from the CC matrix.
 All real eigenvalues and the magnitude of the complex eigenvalues are taken
 as features.
 These values are then sorted by magnitude.
 
\end_layout

\begin_layout Standard
The same is performed using the time-series data (not sure about the normalizati
on).
\end_layout

\end_deeper
\begin_layout Subsection
Classifier
\end_layout

\begin_layout Standard
The chosen method for classification was selected with the help of the scikit-le
arn python machine learning library, which provides a common-interface for
 trying many different classifiers very easily.
 Random Forest offered the best performance.
\end_layout

\begin_layout Standard
The following python scikit-learn classifier was used to train the winning
 submission:
\end_layout

\begin_layout Standard

\emph on
RandomForestClassifier(n_estimators=3000,min_samples_split=1,bootstrap=False,
 random_state=0)
\end_layout

\begin_layout Subsection
Ictal training data generation
\end_layout

\begin_layout Standard
He created additional data using overlapping segments.
 Note, however, that this was not used at the end in the winning submission.
\end_layout

\begin_layout Section
Seizure prediction
\end_layout

\begin_layout Subsection*
Seizure prediction forum discussions
\end_layout

\begin_layout Subsection
Feature extraction
\end_layout

\begin_layout Standard
Didn't find anything relevant.
\end_layout

\begin_layout Subsection
Classifier
\end_layout

\begin_layout Standard
Apparently Random Forest is not performing so well in this case.
 Michael Hills, the winner of the Seizure detection challenge, opted to
 try different classifiers using the scikit-learn Python package and picked
 one (of course didn't mention which) that offered a better performance.
\end_layout

\begin_layout Standard
Another participant suggested: 
\end_layout

\begin_layout Standard
\begin_inset Quotes eld
\end_inset

...you might want to configure your RandomForest to output probabilities instead
 of binary results, maybe by using the regression version instead of classificat
ion version of the algorithm.
 This could help you learn more about the predictions made by your model,
 and get a more fine-grained ROC curve
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
And yet another one said:
\end_layout

\begin_layout Standard
\begin_inset Quotes eld
\end_inset

Hastie et al point out in 'elements of statistical learning' that random
 forests suffer if there are too few good variables relative to noisy variables
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
No clue what this exactly means and whether this actually may be causing
 here some problems.
\end_layout

\begin_layout Subsection*
Literature review
\end_layout

\begin_layout Subsection
Feature extraction
\end_layout

\begin_layout Enumerate
Features based on Lyapunov exponents: short-trem largest Lyapunov exponent,
 
\begin_inset Formula $STL_{max}$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "key-1"

\end_inset

.
 The motivation for using this measure is that EEG signals are highly nonstation
ary and seemingly chaotic.
 The Lyapunov exponents measure the degree of sensitivity to initial conditions
 for a dynamical system.
 The magnitude of the exponents indicate the degree of divergence of trajectorie
s in phase space and the largest Lyapunov exponent is an important indicator
 to characterize a chaotic system.
\end_layout

\begin_layout Enumerate
Note, however, that in 
\begin_inset CommandInset citation
LatexCommand cite
key "key-2"

\end_inset

 they report a poor performance of features based on Lyapunov exponents.
 
\end_layout

\begin_layout Subsection
Classifier
\end_layout

\begin_layout Enumerate
KNN classifier 
\begin_inset CommandInset citation
LatexCommand cite
key "key-1"

\end_inset

: it classifies a new unlabeled sample by comparing the sample with all
 the samples in the two baseline sets (preseizure and interictal states).
 For each EEG epoch in the moving window, the KNN method finds its K-nearest
 (best matching) samples in each baseline, and compares its averaged distances
 to the two groups of K-nearest neighbors.
 The epoch is classified to a baseline that is “closer” to it.
 Distance is measured as simple euclidean distance, T-statistical distance
 or Dynamic time Wrapping of two time series of 
\begin_inset Formula $STL_{max}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Logistic Regression, SVMs and Convolutional Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "key-2"

\end_inset

.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-1"

\end_inset

 Online Seizure Prediction Using an Adaptive Learning Approach.
 Shouyi Wang, Wanpracha Art Chaovalitwongse and Stephen Wong.
 IEEE transactions on knowledge and data engineering, 2013.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-2"

\end_inset

Comparing SVM and Convolutional Networks for Epileptic Seizure Prediction
 from Intracranial EEG.
 Piotr W.
 Mirowski, Yann LeCun, Deepak Madhavan, and Ruben Kuzniecky.
\end_layout

\end_body
\end_document
